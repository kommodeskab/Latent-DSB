# @package _global_
defaults:
  - override /trainer: gpu
  - override /data: fm_celeba
  - override /callbacks: fm_callbacks
  - override /model: fm_latent
  - override /logger: default

project_name: 'flow matching'
task_name: 'test'

callbacks:
  swa:
    _target_: pytorch_lightning.callbacks.StochasticWeightAveraging
    swa_lrs: 1e-2

trainer:
  enable_checkpointing: False
  val_check_interval: 1.0
  log_every_n_steps: 20
  max_epochs: -1
  # limit_val_batches: 1
  # limit_train_batches: 500